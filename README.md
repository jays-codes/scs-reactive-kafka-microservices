# scs-reactive-kafka-microservices
Jay's project/practice repo for Event-driven Microservices using Reactive Kafka and Spring Cloud Stream

#### proj scs-kafka-sandbox (jayaslabs.kafka; SpringBoot 3.5.4, jdk 21; Clud Stream, Spring for Apache Kafka, Lombok, spring-cloud-stream-binder-kafka-reactive)

- Added: application-section4.yaml with key serialization configuration; Modified: application.yaml to use section4 profile
- created pkg: kafka.section4 with enhanced messaging using Message<T> wrapper pattern; KafkaProducer modified to produce Supplier<Flux<Message<String>>> using MessageBuilder for structured message creation with payload, Kafka keys (KafkaHeaders.KEY), and custom headers; KafkaConsumer modified to consume Consumer<Flux<Message<String>>> with printMsgDetails() method for extracting payload via msg.getPayload() and headers via msg.getHeaders(); enables rich metadata transport, message partitioning control, and distributed tracing capabilities; message flow: toMessage() → MessageBuilder.withPayload() → setHeader(KafkaHeaders.KEY) → setHeader(custom) → build() → Flux<Message<String>> → Kafka topic → consumer → printMsgDetails() → extract payload/headers for processing
- [BP] refactor: implement industry best practices for KafkaProcessorTest with hybrid approach; Extract KafkaProcessorTestConfiguration as separate class with @TestConfiguration; Implement hybrid pattern: encapsulated Sinks for input, ConcurrentLinkedQueue for output; Add clean public interface with emitMessage() method for controlled message emission; Replace tight coupling with proper separation of concerns using @ContextConfiguration; Add proper test isolation with @BeforeEach cleanup and queue clearing; Enhance error messages with queue contents for improved debugging; Implement message flow: emitMessage() → inputSink → testProducer → processor → testConsumer → verification;  Add testKafkaProcessorWithSingleMessage() for edge case coverage; Fix timing issues ensuring messages flow after Spring context initialization; solve reactive stream timing issue in previous commit
- created KafkaProcessorTest. Coded original version of integration test using sinks; modified AIT to move properties from test impl (KafkaConsumer/ProducerTest) to AIT (logging, offset.reset)
- created scf KafkaProcessor (kafka.section3) to run within a producer-processor-consumer pipeline -> KafkaProducer with producer():Supplier<Flux<String>> emitting periodic messages; KafkaProcessor with processor():Function<Flux<String>,Flux<String>> using flatMap for concurrent message transformation (toUpperCase); KafkaConsumer with consumer():Consumer<Flux<String>> for final consumption; configured application-section3.yaml with function definition (producer;consumer;processor), topic bindings (input-topic → processor → output-topic), and consumer groups (processor-group, consumer-group); updated application.yaml to use section3 profile
- created KafkaProducerTest & KafkaProducerTestConfiguration; Separate test configuration from test logic using @ContextConfiguration;Implement thread-safe message capture with ConcurrentLinkedQueue; Add proper test isolation with @BeforeEach cleanup; Use reactive testing with StepVerifier and Mono.delay(); Remove tight coupling between test and configuration classes; Maintain clean separation of concerns for better maintainability 
- refactored KafkaConsumerTest to extract config into separate KafkaConsumerTestConfiguration class and referenced via @ContextConfiguration
- modified KafkaConsumerTest to add @TestPropertySource, set properties for: scf.definition, scs.bindings.testProducer-out-0.destination, logging.level.root/jayslabs.kafka. test currently defined for KafkaConsumer.consumer()
- src/test/java: create AbstractIntegrationTest (AIT) base test class (uses @EmbeddedKafka, @SpringbootTest, EmbeddedKafkaBroker - @Autowired); created KafkaConsumerTest (extends AIT, @ExtendWith OutputCaptureExtension) with @Test method testKafkaConsumer(CapturedOutput) - uses: Mono, .delay(), .then(), .fromSupplier(), Duration, output::getOut, Duration, .as(), StepVerifier, consumeNextWith(); Inner class @TestConfiguration TestConfig with testProducer():Supplier<Flux<String>>
- prep workspace for integration test: removed dep:scs-test-binder, added SCSAppTest using @EmbeddedKafka
- added code for setting binding properties via @Bean via SenderOptionsCustomizer (deprecated)
- created KafkaProducer with producer():Supplier<Flux<String>>; modified app.yaml to add to scf.definition, scs.bindings (producer-out-0)
- modified app.yaml to set properties based on kafka.binding (function-0, consumer-in-0)
- added code for setting binding properties via @Bean via ReceiverOptionsCustomizer (deprecated)
- modified app.yaml to define binder specific properties: spring.cloud.stream.kafka.binder.<configuration/producer-properties/consumer-properties>, set "group.instance.id" var
- modified app.yaml to setup for active profiles, + application-section2.yaml, + application.yaml, modified sping app to use scanBasePackages appending active profile var ${sec}
- modified KafkaConsumer to add another function bean - function():Function<Flux<String>,Mono<Void>>; modified application.yaml: added binding for function(), and set spring.cloud.function.definition to use function
- pkg: kafka.section2: created KafkaConsumer (@Configuration) with consumer():Consumer<Flux<String>> (@Bean); defined bindings in application.yaml: spring.cloud.stream.bindings
- initial project commit; updated pom reference for spring-cloud-stream-binder-kafka-reactive; readme update

#### proj folder: kafka-setup
- added docker-compose.yaml to setup docker (image: vinsdocker/kafka), volumes r
eferences server.properties; added /data/ to gitignore

#### repo: scs-reactive-kafka-microservices